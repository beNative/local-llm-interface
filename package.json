{
  "name": "local-llm-interface",
  "version": "1.0.0",
  "description": "An interface to chat with locally installed LLMs serviced through Ollama or LMStudio. This Electron app allows configuration of the service endpoint and provides an overview of available models.",
  "main": "dist/electron/main.js",
  "author": "",
  "license": "MIT",
  "scripts": {
    "postinstall": "electron-builder install-app-deps",
    "start": "npm run build && electron .",
    "build": "tsc",
    "dist": "npm run build && electron-builder",
    "dist:win": "npm run build && electron-builder --win"
  },
  "devDependencies": {
    "@types/node": "^20.12.12",
    "electron": "^31.0.1",
    "electron-builder": "^24.13.3",
    "typescript": "^5.4.5"
  },
  "build": {
    "appId": "com.localllm.interface",
    "productName": "Local LLM Interface",
    "files": [
      "dist/electron/",
      "index.html",
      "App.tsx",
      "index.tsx",
      "constants.ts",
      "types.ts",
      "electron.d.ts",
      "components/",
      "services/"
    ],
    "directories": {
      "output": "release"
    },
    "win": {
      "target": "nsis"
    }
  }
}
